+++
title = "Delega tu filosofía a la AI!"
date = 2025-11-13T12:00:00-03:00
draft = false
tags = ["Philosophy", "AI", "Society"]
categories = ["Society", "Philosophy"]
metadescription = 'Delega tu filosofía a la AI!'
metakeywords = 'ai, ia, filosofia, pensamiento, delega, aprendizaje, inteligencia, artificial'
+++

La narrativa dominante en el último tiempo fue que la IA nos va a reemplazar. Robots, algoritmos, máquinas que nos dejarán obsoletos. Incluso titulares hablan de un 'desplazamiento laboral', 'automatización de empleos', 'el fin de la fuerza de trabajo humana'. Aunque no estoy en nada de acuerdo con esos titulares, malinterpreta fundamentalmente qué es la IA, de más está decir que no nos va a reemplazar y tampoco es un agente independiente que razona para desarrollar tareas.

**TLDR;** 
*Desde mi punto de vista la IA es un nuevo nivel de abstracción en nuestra cadena cognitiva, una capa más en el stack que venimos desarrollando hace décadas con el avance de la tecnología.
Pero acá está la trampa sutil: cada nivel de abstracción esconde un nivel de comprensión anterior.*

## La inteligencia artificial como un nivel de abstracción
Cada capa de simplificación nos permite operar a un nivel más alto sin necesidad de comprender los detalles subyacentes, al menos en la ingeniería. Una persona no necesita entender cómo funciona el motor para manejar un auto; el mismo tablero que tenés en frente es una capa de abstracción que oculta la complejidad. Los sistemas operativos hacen lo mismo entre el hardware y nuestras aplicaciones de uso diario, es una estrategia extraordinariamente efectiva para escalar complejidad, pero tiene un coste que rara vez contabilizamos: la pérdida de comprensión profunda.

La IA contemporánea funciona exactamente como estas capas de abstracción tradicionales. Los modelos grandes del lenguaje están justo en medio entre nuestras intenciones declarativas *(prompts)* y los resultados. En casos como estudiantes que no entienden aún el tópico a tratar, están efectivamente, externalizando su pensamiento.

Tampoco quiero que se malinterprete, **la IA es una herramienta muy poderosa**, así como una persona que es muy buena haciendo cálculos mentales alguien con una calculadora lo va a dejar atrás, alguien utilizando inteligencia artificial va a dejarte atrás en el mundo moderno en tu campo. En mi camino como programador comencé jugando con Assembly que es la capa "más baja" entre lo físico y el software, hoy día es encomiable conocer a alguien con esta habilidad pero decir que podemos ponernos a optimizar a tan bajo nivel realmente a nadie le importa, se crearon compiladores y herramientas tan pulidas que dejó de ser importante.

Cuando usamos una calculadora, no necesitamos entender qué es una división. Cuando usamos una IA, no necesitamos ejercitar razonamiento. **El reemplazo no viene de la máquina intentando ser inteligente; viene de nosotros renunciando a serlo.**

---

![Outsource Philosophy](/blog/outsource-philosophy.png)

### No podés delegar lo que sos
Como contexto de la imagen anterior irónicamente generada por AI, esta es la intuición más provocadora del debate actual: **el pensamiento no es una tarea que pueda externalizarse como cualquier otra**. Cuando delegamos el cálculo de un salario a un software, ganamos eficiencia sin perder capacidad cognitiva crítica. Pero cuando delegamos el razonamiento, el análisis, la síntesis de ideas, estamos perdiendo algo más fundamental: la plasticidad neuronal que hacen que ese razonamiento sea posible, a fin de cuenta estamos hablando de un músculo.

Y claro está que esto pasa constantemente en el mundo moderno, hoy día no voy a ningún lugar en mi coche sin antes poner el Google Maps, aunque haya ido a ese lugar mil veces y sepa el camino de memoria. Google Maps conoce mejor que yo la mejor ruta, porque hubo un accidente, porque hay demasiado tráfico en una zona específica, etc. y tampoco recuerdo el 90% de mi agenda telefónica más que dos o tres números específicos. El razonamiento en base a esta premisa es muy simple, **cada cosa que delegamos a la tecnología es una capacidad que perdemos**, por ende tenemos que ser estratégicos en qué cosas delegamos.

### La falsa dicotomía de la eficiencia
Existe una tentación casi irresistible de aceptar este tradeoff. Sí, olvidamos cómo razonar o hacer actividades creativas, pero somos extremadamente rápidos y eficientes, cualidades que al mundo actual te vuelve invaluable ¿No es ese un trueque justo?

Ya les digo yo que no, **el pensamiento crítico y la capacidad creativa no es un lujo; es el fundamento sobre el cual se construye todo lo demás**. [^1]

Cuando confiamos ciegamente en la IA y sus recomendaciones sin evaluar críticamente los supuestos, no estamos siendo más eficientes, nos estamos volviendo vulnerables a que unas cuantas expresiones matemáticas sencillas con un porcentaje de variabilidad llamado temperatura decida por nosotros aleatoriamente, dando problemas que luego gente con capacidad de razonamiento tendrá que resolver.

Existe una propuesta emergente en la educación: usar IA de manera estratégica, como un andamio ("scaffolding") que se retira gradualmente, no como un reemplazo permanente. Usar IA para calibrar la carga cognitiva *(no tanto que nos abrume)*, pero lo suficiente para crear el estrés que estimula el crecimiento. Como alcanzar ese "sweet spot" de dificultad óptima que nos permita crecer. [^2]

Pero esto requiere una resistencia cultural que es difícil de imaginar en la era de la máxima eficiencia. Requiere valorar el pensamiento lento, el proceso difícil, la posibilidad de equivocarse. Requiere decir "no" a la conveniencia cuando esa conveniencia cuesta más de lo que gana.

## Conclusión
Al final la pregunta no es si deberíamos utilizar la inteligencia artificial sino más bien "¿qué tipo de persona quiero ser?". Cada vez que delegamos un acto a una máquina nos convertimos en algo más simple. Nos volvemos menos capaces de sorprendernos a nosotros mismos, menos capacitados para navegar la incertidumbre y menos resilientes frente a lo inesperado. Vamos, lo más interesante que tiene la vida.

[^1]: https://www.psypost.org/ai-tools-may-weaken-critical-thinking-skills-by-encouraging-cognitive-offloading-study-suggests/

[^2]: https://phys.org/news/2025-01-ai-linked-eroding-critical-skills.html